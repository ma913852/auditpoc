<!-- ENHANCED FIELDWORK UI WITH AI AUTO-TAGGING -->
<!-- Multi-modal input: Text + Image + Audio -->

<style>
.recording { animation: pulse-red 1.5s ease-in-out infinite; }
@keyframes pulse-red {
    0%, 100% { background-color: #DC2626; }
    50% { background-color: #EF4444; }
}
.ai-suggestion {
    animation: fadeIn 0.5s ease-in;
}
@keyframes fadeIn {
    from { opacity: 0; transform: translateY(-10px); }
    to { opacity: 1; transform: translateY(0); }
}
</style>

<!-- Add to existing observation form section -->
<div id="obsFormState" class="hidden flex-1 flex flex-col overflow-hidden">
    <div class="bg-gradient-to-r from-purple-600 to-blue-600 text-white p-4">
        <h2 class="font-bold text-xl">üìù Smart Observation Capture</h2>
        <p class="text-xs text-purple-100 mt-1">AI will analyze and suggest requirement matches</p>
    </div>
    
    <div class="flex-1 overflow-y-auto p-4 space-y-4">
        
        <!-- Multi-Modal Input Section -->
        <div class="bg-gradient-to-br from-blue-50 to-purple-50 border-2 border-purple-200 rounded-lg p-4">
            <h4 class="text-sm font-bold text-purple-800 mb-3">üìä Capture Evidence (Multi-Modal)</h4>
            
            <!-- Text Input -->
            <div class="mb-3">
                <label class="block text-sm font-semibold text-slate-700 mb-2">‚úçÔ∏è Written Observation *</label>
                <textarea id="obsTextAI" rows="4" class="w-full px-3 py-2 border border-slate-300 rounded-lg focus:ring-2 focus:ring-purple-500" placeholder="Describe what you observed... (AI will analyze this)"></textarea>
            </div>
            
            <!-- Image Capture -->
            <div class="mb-3">
                <label class="block text-sm font-semibold text-slate-700 mb-2">üì∏ Photo Evidence (Optional)</label>
                <div class="flex gap-2">
                    <input type="file" id="obsImageInput" accept="image/*" capture="environment" class="hidden" onchange="handleImageCapture(event)">
                    <button onclick="document.getElementById('obsImageInput').click()" class="flex-1 px-3 py-2 bg-blue-500 text-white rounded-lg text-sm font-semibold hover:bg-blue-600 flex items-center justify-center">
                        <svg class="w-4 h-4 mr-2" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M3 9a2 2 0 012-2h.93a2 2 0 001.664-.89l.812-1.22A2 2 0 0110.07 4h3.86a2 2 0 011.664.89l.812 1.22A2 2 0 0018.07 7H19a2 2 0 012 2v9a2 2 0 01-2 2H5a2 2 0 01-2-2V9z"></path>
                            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15 13a3 3 0 11-6 0 3 3 0 016 0z"></path>
                        </svg>
                        Take Photo
                    </button>
                    <button onclick="clearImage()" class="px-3 py-2 bg-slate-200 text-slate-700 rounded-lg text-sm hover:bg-slate-300">Clear</button>
                </div>
                <div id="imagePreview" class="hidden mt-2">
                    <img id="previewImg" class="w-full max-h-48 object-contain rounded-lg border-2 border-purple-200">
                    <p class="text-xs text-slate-600 mt-1">Image captured - AI will analyze this</p>
                </div>
                <input type="text" id="imageDescription" placeholder="Describe what's in the photo (or let AI analyze)" class="hidden mt-2 w-full px-3 py-2 border border-slate-300 rounded-lg text-sm">
            </div>
            
            <!-- Audio Recording -->
            <div class="mb-3">
                <label class="block text-sm font-semibold text-slate-700 mb-2">üé§ Voice Note (Optional)</label>
                <div class="flex gap-2">
                    <button id="recordBtn" onclick="toggleRecording()" class="flex-1 px-3 py-2 bg-red-500 text-white rounded-lg text-sm font-semibold hover:bg-red-600 flex items-center justify-center">
                        <svg class="w-4 h-4 mr-2" fill="currentColor" viewBox="0 0 20 20">
                            <path fill-rule="evenodd" d="M7 4a3 3 0 016 0v4a3 3 0 11-6 0V4zm4 10.93A7.001 7.001 0 0017 8a1 1 0 10-2 0A5 5 0 015 8a1 1 0 00-2 0 7.001 7.001 0 006 6.93V17H6a1 1 0 100 2h8a1 1 0 100-2h-3v-2.07z" clip-rule="evenodd"></path>
                        </svg>
                        <span id="recordBtnText">Start Recording</span>
                    </button>
                    <button onclick="clearAudio()" class="px-3 py-2 bg-slate-200 text-slate-700 rounded-lg text-sm hover:bg-slate-300">Clear</button>
                </div>
                <div id="audioPreview" class="hidden mt-2 p-3 bg-slate-50 rounded-lg border border-slate-200">
                    <div class="flex items-center justify-between">
                        <span class="text-sm text-slate-700">üé§ Recording: <span id="recordDuration">0:00</span></span>
                        <button onclick="playRecording()" class="text-sm text-blue-600 hover:text-blue-800">‚ñ∂ Play</button>
                    </div>
                </div>
                <textarea id="audioTranscription" placeholder="Audio transcription will appear here (or type manually)" class="hidden mt-2 w-full px-3 py-2 border border-slate-300 rounded-lg text-sm" rows="2"></textarea>
            </div>
            
            <!-- AI Analysis Button -->
            <div class="pt-3 border-t border-purple-200">
                <button onclick="analyzeWithAI()" id="analyzeBtn" class="w-full px-4 py-3 bg-gradient-to-r from-purple-600 to-blue-600 text-white rounded-lg font-bold text-sm hover:from-purple-700 hover:to-blue-700 flex items-center justify-center">
                    <svg class="w-5 h-5 mr-2" fill="none" stroke="currentColor" viewBox="0 0 24 24">
                        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M13 10V3L4 14h7v7l9-11h-7z"></path>
                    </svg>
                    Analyze with AI
                </button>
                <p class="text-xs text-center text-slate-500 mt-2">AI will match to requirements and suggest tags</p>
            </div>
        </div>
        
        <!-- AI Suggestions Panel (Hidden until analysis) -->
        <div id="aiSuggestionsPanel" class="hidden bg-gradient-to-br from-green-50 to-blue-50 border-2 border-green-300 rounded-lg p-4 ai-suggestion">
            <div class="flex items-center justify-between mb-3">
                <h4 class="text-sm font-bold text-green-800">ü§ñ AI Analysis Complete</h4>
                <button onclick="acceptAISuggestions()" class="px-3 py-1 bg-green-600 text-white rounded-lg text-xs font-semibold hover:bg-green-700">Accept All</button>
            </div>
            
            <div id="aiSuggestionsContent" class="space-y-3">
                <!-- Populated by JavaScript -->
            </div>
        </div>
        
        <!-- Location & Metadata -->
        <div class="grid grid-cols-2 gap-3">
            <div>
                <label class="block text-sm font-semibold text-slate-700 mb-2">üìç Location</label>
                <input type="text" id="obsLocationAI" class="w-full px-3 py-2 border border-slate-300 rounded-lg text-sm" placeholder="e.g., Grade A Filling Room 2">
            </div>
            <div>
                <label class="block text-sm font-semibold text-slate-700 mb-2">üë§ Interviewed</label>
                <input type="text" id="obsInterviewedAI" class="w-full px-3 py-2 border border-slate-300 rounded-lg text-sm" placeholder="e.g., Sarah Chen">
            </div>
        </div>
        
        <!-- Compliance Status (Auto-filled by AI) -->
        <div>
            <label class="block text-sm font-semibold text-slate-700 mb-2">üéØ Compliance Status <span id="aiSuggestedStatus" class="text-xs text-green-600"></span></label>
            <div class="space-y-2">
                <label class="flex items-center p-3 border-2 border-slate-200 rounded-lg cursor-pointer hover:bg-slate-50">
                    <input type="radio" name="obsStatusAI" value="compliant" class="mr-3">
                    <span class="text-green-700 font-medium">‚úì Compliant</span>
                </label>
                <label class="flex items-center p-3 border-2 border-slate-200 rounded-lg cursor-pointer hover:bg-slate-50">
                    <input type="radio" name="obsStatusAI" value="gap" checked class="mr-3">
                    <span class="text-amber-700 font-medium">‚ö†Ô∏è Gap Identified</span>
                </label>
                <label class="flex items-center p-3 border-2 border-slate-200 rounded-lg cursor-pointer hover:bg-slate-50">
                    <input type="radio" name="obsStatusAI" value="non-compliant" class="mr-3">
                    <span class="text-red-700 font-medium">‚úó Non-Compliant</span>
                </label>
            </div>
        </div>
        
        <!-- Severity (Auto-filled by AI) -->
        <div>
            <label class="block text-sm font-semibold text-slate-700 mb-2">Severity Level <span id="aiSuggestedSeverity" class="text-xs text-green-600"></span></label>
            <select id="obsSeverityAI" class="w-full px-3 py-2 border border-slate-300 rounded-lg">
                <option value="minor">Minor</option>
                <option value="major" selected>Major</option>
                <option value="critical">Critical</option>
            </select>
        </div>
        
        <!-- AI-Suggested Citations -->
        <div id="aiCitationsSection" class="hidden bg-blue-50 border border-blue-200 rounded-lg p-3">
            <h5 class="text-xs font-semibold text-blue-800 mb-2">üìö Additional Citations (AI-Suggested)</h5>
            <div id="aiCitationsList" class="space-y-1">
                <!-- Populated by JavaScript -->
            </div>
        </div>
        
        <!-- AI Analysis Summary -->
        <div id="aiAnalysisSection" class="hidden bg-purple-50 border border-purple-200 rounded-lg p-3">
            <h5 class="text-xs font-semibold text-purple-800 mb-2">üîç AI Analysis</h5>
            <p id="aiAnalysisText" class="text-xs text-purple-700"></p>
        </div>
        
        <!-- AI Recommendations -->
        <div id="aiRecommendationsSection" class="hidden bg-amber-50 border border-amber-200 rounded-lg p-3">
            <h5 class="text-xs font-semibold text-amber-800 mb-2">üí° Recommendations</h5>
            <ul id="aiRecommendationsList" class="list-disc list-inside text-xs text-amber-700 space-y-1">
                <!-- Populated by JavaScript -->
            </ul>
        </div>
    </div>
    
    <!-- Form Actions -->
    <div class="p-4 border-t border-slate-200 bg-slate-50 flex gap-3">
        <button onclick="cancelObservationAI()" class="flex-1 px-4 py-3 bg-slate-300 text-slate-700 rounded-lg font-semibold hover:bg-slate-400">Cancel</button>
        <button onclick="saveObservationAI()" class="flex-1 px-4 py-3 bg-gradient-to-r from-purple-600 to-blue-600 text-white rounded-lg font-semibold hover:from-purple-700 hover:to-blue-700">üíæ Save Observation</button>
    </div>
</div>

<script>
// AI-ENHANCED OBSERVATION CAPTURE
// ============================================================================

let capturedImage = null;
let capturedAudio = null;
let aiAnalysisResult = null;
let mediaRecorder = null;
let audioChunks = [];
let recordingStartTime = null;
let recordingInterval = null;
let currentRequirementForAI = null;

// Image Capture
function handleImageCapture(event) {
    const file = event.target.files[0];
    if (!file) return;
    
    const reader = new FileReader();
    reader.onload = function(e) {
        capturedImage = e.target.result;
        document.getElementById('previewImg').src = capturedImage;
        document.getElementById('imagePreview').classList.remove('hidden');
        document.getElementById('imageDescription').classList.remove('hidden');
        
        // Auto-describe (placeholder - in production, use vision API)
        document.getElementById('imageDescription').value = "Photo captured - will be analyzed by AI";
    };
    reader.readAsDataURL(file);
}

function clearImage() {
    capturedImage = null;
    document.getElementById('obsImageInput').value = '';
    document.getElementById('imagePreview').classList.add('hidden');
    document.getElementById('imageDescription').classList.add('hidden');
}

// Audio Recording
async function toggleRecording() {
    const btn = document.getElementById('recordBtn');
    const btnText = document.getElementById('recordBtnText');
    
    if (!mediaRecorder || mediaRecorder.state === 'inactive') {
        // Start recording
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            mediaRecorder = new MediaRecorder(stream);
            audioChunks = [];
            
            mediaRecorder.ondataavailable = (event) => {
                audioChunks.push(event.data);
            };
            
            mediaRecorder.onstop = () => {
                const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
                capturedAudio = URL.createObjectURL(audioBlob);
                document.getElementById('audioPreview').classList.remove('hidden');
                document.getElementById('audioTranscription').classList.remove('hidden');
                
                // Placeholder transcription
                document.getElementById('audioTranscription').value = "[Audio recorded - transcription will be generated]";
                
                // Stop tracking
                stream.getTracks().forEach(track => track.stop());
                clearInterval(recordingInterval);
            };
            
            mediaRecorder.start();
            recordingStartTime = Date.now();
            
            // Update UI
            btn.classList.add('recording');
            btnText.innerText = 'Stop Recording';
            
            // Start duration tracking
            recordingInterval = setInterval(updateRecordingDuration, 1000);
            
        } catch (error) {
            console.error('Error accessing microphone:', error);
            alert('Could not access microphone. Please grant permission.');
        }
    } else {
        // Stop recording
        mediaRecorder.stop();
        btn.classList.remove('recording');
        btnText.innerText = 'Start Recording';
    }
}

function updateRecordingDuration() {
    const elapsed = Math.floor((Date.now() - recordingStartTime) / 1000);
    const minutes = Math.floor(elapsed / 60);
    const seconds = elapsed % 60;
    document.getElementById('recordDuration').innerText = `${minutes}:${seconds.toString().padStart(2, '0')}`;
}

function clearAudio() {
    if (mediaRecorder && mediaRecorder.state === 'recording') {
        mediaRecorder.stop();
    }
    capturedAudio = null;
    audioChunks = [];
    document.getElementById('audioPreview').classList.add('hidden');
    document.getElementById('audioTranscription').classList.add('hidden');
    document.getElementById('recordBtn').classList.remove('recording');
    document.getElementById('recordBtnText').innerText = 'Start Recording';
}

function playRecording() {
    if (capturedAudio) {
        const audio = new Audio(capturedAudio);
        audio.play();
    }
}

// AI Analysis
async function analyzeWithAI() {
    const obsText = document.getElementById('obsTextAI').value.trim();
    const imageDesc = document.getElementById('imageDescription').value.trim();
    const audioTrans = document.getElementById('audioTranscription').value.trim();
    
    if (!obsText && !imageDesc && !audioTrans) {
        alert('Please enter at least one form of observation (text, image description, or audio)');
        return;
    }
    
    // Show loading state
    const analyzeBtn = document.getElementById('analyzeBtn');
    const originalText = analyzeBtn.innerHTML;
    analyzeBtn.disabled = true;
    analyzeBtn.innerHTML = `
        <svg class="animate-spin w-5 h-5 mr-2 inline" fill="none" viewBox="0 0 24 24">
            <circle class="opacity-25" cx="12" cy="12" r="10" stroke="currentColor" stroke-width="4"></circle>
            <path class="opacity-75" fill="currentColor" d="M4 12a8 8 0 018-8V0C5.373 0 0 5.373 0 12h4zm2 5.291A7.962 7.962 0 014 12H0c0 3.042 1.135 5.824 3 7.938l3-2.647z"></path>
        </svg>
        Analyzing with AI...
    `;
    
    try {
        const response = await fetch('/api/observations/analyze', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json'
            },
            body: JSON.stringify({
                observationText: obsText,
                imageDescription: imageDesc,
                audioTranscription: audioTrans,
                requirements: fieldworkRequirements
            })
        });
        
        const result = await response.json();
        
        if (result.success) {
            aiAnalysisResult = result.analysis;
            displayAISuggestions(result.analysis);
        } else {
            alert('AI analysis failed: ' + result.error);
        }
        
    } catch (error) {
        console.error('Error analyzing observation:', error);
        alert('Failed to analyze observation: ' + error.message);
    } finally {
        analyzeBtn.disabled = false;
        analyzeBtn.innerHTML = originalText;
    }
}

function displayAISuggestions(analysis) {
    // Show suggestions panel
    document.getElementById('aiSuggestionsPanel').classList.remove('hidden');
    
    // Build suggestions content
    let content = '';
    
    // Matched requirements
    if (analysis.matched_requirements && analysis.matched_requirements.length > 0) {
        content += '<div class="mb-3">';
        content += '<h5 class="text-xs font-semibold text-green-800 mb-2">üéØ Matched Requirements:</h5>';
        analysis.matched_requirements.forEach(match => {
            const req = fieldworkRequirements.find(r => r.id === match.requirement_id);
            if (req) {
                const confidence = Math.round(match.confidence * 100);
                content += `
                    <div class="p-2 bg-white rounded border border-green-200 mb-2">
                        <div class="flex justify-between items-start">
                            <div>
                                <span class="text-xs font-semibold text-green-700">${req.id}</span>
                                <span class="ml-2 text-xs text-green-600">${confidence}% match</span>
                            </div>
                        </div>
                        <p class="text-xs text-slate-600 mt-1">${match.reasoning}</p>
                    </div>
                `;
                
                // Auto-select the first matched requirement
                if (analysis.matched_requirements[0].requirement_id === match.requirement_id) {
                    currentRequirementForAI = req;
                }
            }
        });
        content += '</div>';
    }
    
    // Key findings
    if (analysis.key_findings && analysis.key_findings.length > 0) {
        content += '<div class="mb-2">';
        content += '<h5 class="text-xs font-semibold text-blue-800 mb-1">üîç Key Findings:</h5>';
        content += '<ul class="list-disc list-inside text-xs text-blue-700 space-y-0.5">';
        analysis.key_findings.forEach(finding => {
            content += `<li>${finding}</li>`;
        });
        content += '</ul></div>';
    }
    
    document.getElementById('aiSuggestionsContent').innerHTML = content;
    
    // Update status and severity indicators
    if (analysis.compliance_status) {
        const statusLabels = {
            'compliant': '(AI suggests: Compliant)',
            'gap': '(AI suggests: Gap)',
            'non_compliant': '(AI suggests: Non-Compliant)'
        };
        document.getElementById('aiSuggestedStatus').innerText = statusLabels[analysis.compliance_status] || '';
    }
    
    if (analysis.severity) {
        document.getElementById('aiSuggestedSeverity').innerText = `(AI suggests: ${analysis.severity})`;
    }
    
    // Show additional citations
    if (analysis.additional_citations && analysis.additional_citations.length > 0) {
        document.getElementById('aiCitationsSection').classList.remove('hidden');
        let citationsHTML = '';
        analysis.additional_citations.forEach(citation => {
            citationsHTML += `<div class="text-xs text-blue-700">‚Ä¢ ${citation}</div>`;
        });
        document.getElementById('aiCitationsList').innerHTML = citationsHTML;
    }
    
    // Show analysis
    if (analysis.analysis) {
        document.getElementById('aiAnalysisSection').classList.remove('hidden');
        document.getElementById('aiAnalysisText').innerText = analysis.analysis;
    }
    
    // Show recommendations
    if (analysis.recommendations && analysis.recommendations.length > 0) {
        document.getElementById('aiRecommendationsSection').classList.remove('hidden');
        let recsHTML = '';
        analysis.recommendations.forEach(rec => {
            recsHTML += `<li>${rec}</li>`;
        });
        document.getElementById('aiRecommendationsList').innerHTML = recsHTML;
    }
}

function acceptAISuggestions() {
    if (!aiAnalysisResult) return;
    
    // Auto-fill compliance status
    if (aiAnalysisResult.compliance_status) {
        const statusValue = aiAnalysisResult.compliance_status === 'non_compliant' ? 'non-compliant' : aiAnalysisResult.compliance_status;
        document.querySelector(`input[name="obsStatusAI"][value="${statusValue}"]`).checked = true;
    }
    
    // Auto-fill severity
    if (aiAnalysisResult.severity) {
        document.getElementById('obsSeverityAI').value = aiAnalysisResult.severity;
    }
    
    alert('‚úì AI suggestions accepted! Review and save when ready.');
}

async function saveObservationAI() {
    const obsText = document.getElementById('obsTextAI').value.trim();
    const location = document.getElementById('obsLocationAI').value.trim();
    const interviewed = document.getElementById('obsInterviewedAI').value.trim();
    const status = document.querySelector('input[name="obsStatusAI"]:checked').value;
    const severity = document.getElementById('obsSeverityAI').value;
    
    if (obsText.length < 50) {
        alert('Observation text must be at least 50 characters');
        return;
    }
    
    if (!currentRequirementForAI && (!aiAnalysisResult || !aiAnalysisResult.matched_requirements || aiAnalysisResult.matched_requirements.length === 0)) {
        alert('Please run AI analysis first to match to a requirement');
        return;
    }
    
    // Use AI-matched requirement or manually selected one
    const linkedReq = currentRequirementForAI || fieldworkRequirements.find(r => 
        r.id === aiAnalysisResult.matched_requirements[0].requirement_id
    );
    
    const observationData = {
        linkedRequirement: linkedReq,
        observationText: obsText,
        complianceStatus: status,
        severity: status === 'compliant' ? 'minor' : severity,
        category: linkedReq.category,
        location: location,
        interviewed: interviewed,
        evidence: [],
        aiAnalysis: aiAnalysisResult  // Store AI analysis with observation
    };
    
    try {
        const response = await fetch('/api/observations', {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json'
            },
            body: JSON.stringify(observationData)
        });
        
        const result = await response.json();
        
        if (result.success) {
            fieldworkObservations.push(result.observation);
            displayFieldworkRequirements();
            updateFieldworkStats();
            
            // Show success and reset form
            alert('‚úì Observation saved successfully with AI analysis!');
            resetAIForm();
            closeObservationDetail();
        } else {
            alert('Failed to save observation: ' + result.error);
        }
    } catch (error) {
        alert('Error saving observation: ' + error.message);
    }
}

function resetAIForm() {
    document.getElementById('obsTextAI').value = '';
    document.getElementById('obsLocationAI').value = '';
    document.getElementById('obsInterviewedAI').value = '';
    document.getElementById('aiSuggestionsPanel').classList.add('hidden');
    document.getElementById('aiCitationsSection').classList.add('hidden');
    document.getElementById('aiAnalysisSection').classList.add('hidden');
    document.getElementById('aiRecommendationsSection').classList.add('hidden');
    clearImage();
    clearAudio();
    aiAnalysisResult = null;
    currentRequirementForAI = null;
}

function cancelObservationAI() {
    resetAIForm();
    document.getElementById('obsFormState').classList.add('hidden');
    document.getElementById('obsEmptyState').classList.remove('hidden');
}
</script>

